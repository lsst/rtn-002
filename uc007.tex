{\bf Use Case:} 007 A Science-Driven Modification to a Data Product \\

{\bf Characteristic Information} \\
Trigger: A manuscript is published in teh literature that highlights and issue with Rubin Observatory Data Release products. This paper is sceen by a CET member, who passes it along to the Community Scientist and Science Collaboration with the relevant expertise. \\
Goal in Context: While the Data Releases will be subject to verification adn validation before release, it is inevitable that sub-optimal outcomes for certain science goals will be identified as a result of data processing decisions that were taken (or weren't even considered).  The CET and the DRP team need to implement processes to (1) assess the possible impacts of alterations to the code baes that solve the issue, and (2) if possible, incorporate code changes that mitigate the emergent scientific issue while not compromising overal DRP results. \\
Primary Actor: The CET member with primary expertise in transients. \\
Scope: Data Release Production \\
Level: \\
Preconditions: A Data Release has occurred, with sufficient time passed for scientists to carry reseach projects throught to publication. \\
Success End Condition: The DRP tema implements and tests and algorithmic change that solves the problem. \\
Failed End Condition: A solution is either not identified, or is deemed deterimental to other aspects of data quality, and the systematic offset in nuclear transient occurrence rates with galaxy host types remains unchanged. \\

{\bf Main Success Scenario} \\
1. A manuscript is published in the literature that highlights a systematic offset in the detection efficiency of nuclear transients in different types of host galazies with Rubin Observatory Data Release products. \\
2. This paper is brought to the attention of a CET member, who creates an Issue Ticket assigned to the Community Scientist(s) and Science Collaboration(s) with the relevant expertise (in this case, predominantly time-domain science and the TVS SC). \\
3. The Community Scientist and other relevant parties investigate the issue and identify a possible cause in the DM pipelines. \\
4. The ticket is discussed with DM developers, who identify possible improvements to mitigate the issue, and consider the possible side effects of implementing those changes. \\
5. DM developers implement the code changes on a ticket branch, and the relevant CET and/or TVS-SC verify that the new algoithm decreases (or removes) the systematic offsets with host galaxy type from the delivered detection efficiencies, while not adversely affecting other pipeline outputs. \\
6. The changes are merged to the science pipelines, and one of the relevant parties defines a metric that can be monitored each time a new version of the Science Pipelines and DRP is released. \\
7.  The CET member details the mitigation and demonstrates its outcome in a public-facing document (e.g., a DM Tech Note or similar), and the issue is closed. \\

{\bf Extensions} \\
Altered Step 5.1: Relevvant CET and/or TVS-SC members test the new algorithm to assess whether it improves the formerly low detection efficiencies in certain types of host galaxies.  During this verification, it is discovered that the changes that were made (e.g., lowering detection thresholds near resolved galaxies) adversely affected other scientific data products. \\
Altered Step 5.2: It is decided that it is not acceptable to sacrifice data quality of other pipeline products to solve this issue with galactic transients.  As an alternative, a methood is devised that does not require new or altered measurements, but instead uses existing measurements such as offset from the nearest galaxy, color, morphology, etc. to derive a classification scheme that more accurately captures the subtlety of identifying transients in galaxy nuclei. \\

{\bf Sub-Variations} \\
\\

{\bf Related Information} (Optional) \\
Priority: Not urgent, but important to have a process to deal with emergent science effects such as this.  The amount of effort to be spent will depend on how frequency issues like this come to our attention. \\
Performance Target: 1-3 months \\
Frequency: 4-8 times per year (most likely all clustered in a period shortly after data releases) \\
Superordinate Use Case:  \\
Subordinate Use Cases: \\
Channel to primary actor: Personal communication (email, Slack, or during regular meetings) to CET or individual Community Scientist \\
Secondary Actors: Data Management developer(s), interested Science Collaboration members \\
Channel to Secondary Actors: Email or Slack (perhaps first passing through the DM-SST) \\

{\bf Open Issues} (Optional) \\

{\bf Schedule} \\
Due Date: \\
